import logging
from pathlib import Path
import shutil
from time import perf_counter as timer

import numpy
from ansys.dpf import core as dpf
from ansys.mapdl import core as mapdl
from numpy.typing import NDArray

from oamc.enums import Axis, ElementType
from oamc.fea.analysis import Analysis
from oamc.fea.bc import BC
from oamc.fea.material import TransverselyIsotropicMaterial
from oamc.fea.mesh import Mesh

logger = logging.getLogger(__name__)


def tokenize(line: str, sep: str | None = None) -> list[str]:
    return [token.strip() for token in line.split(sep)]


class DSReader:
    """Read ds.dat files generated by Ansys.

    Usage:
    >>> with DSReader("path/to/ds.dat") as reader:
    >>>     mesh = reader.get_mesh()
    >>>     fea = reader.get_fea()
    """

    def __init__(self, path):
        """Initialize a new instance.

        :param path: path to the ds.dat file
        """
        self.path = Path(path).resolve()
        if not self.path.exists():
            raise FileNotFoundError(self.path)
        self.mapdl = None

    def __enter__(self):
        # Insert OUTRES,NODE,ALL command, so the database contains
        # equivalent nodal loads after solving:
        with open(self.path, "r") as file:
            lines = file.readlines()
        in_outres_block = False
        for index, line in enumerate(lines):
            if line.lower().startswith("outres"):
                if line.lower().replace(" ", "") == "outres,nload,all\n":
                    break
                in_outres_block = True
            elif in_outres_block:
                lines.insert(index, "outres,nload,all\n")
                break
        with open(self.path, "w") as file:
            file.writelines(lines)

        # Create a directory for working files:
        self.run_location = self.path.parent / "temp"
        self.run_location.mkdir(parents=True, exist_ok=True)

        start = timer()

        # Launch a new MAPDL session:
        self.mapdl = mapdl.launch_mapdl(
            run_location=str(self.run_location),
            loglevel="WARNING",
            override=True,
            cleanup_on_exit=True,
            start_timeout=60,
        )

        logger.info(f"Mechanical APDL launched in {round(timer() - start, 3)} seconds.")

        # Clear the database (not necessary as this is a new instance but safety first):
        self.mapdl.clear()

        # Enter PREP7:
        self.mapdl.prep7()

        start = timer()

        # Read the ds.dat file:
        self.mapdl.input(str(self.path))

        # The model is automatically solved as the ds.dat file contains a SOLVE command.

        logger.info(f"Model read and solved by MAPDL in {round(timer() - start, 3)} seconds.")

        # Exit the current processor:
        self.mapdl.finish()

        # Enter POST1:
        self.mapdl.post1()

        # Read the last data set:
        self.mapdl.set("LAST")

        # Select all entities:
        self.mapdl.allsel("ALL", "ALL")

        # Disable headers in string output such as PRNLD:
        self.mapdl.header("OFF")

        # Maximum page dimensions for continuous output:
        self.mapdl.page(iline=1e9, ichar=132, bline=-1, bchar=240)

        return self

    def __exit__(self, exc_type, exc, tb):
        if self.mapdl is not None:
            self.mapdl.exit()
        dpf.server.shutdown_all_session_servers()
        shutil.rmtree(self.run_location)

    def get_mesh(self) -> Mesh:
        # Get nodes:
        nodes = self.mapdl.mesh.nodes

        # Read material data:
        # mdict = {}
        # with open(self.path, "r") as file:
        #     for line in file:
        #         if line.startswith("MP,"):
        #             tokens = tokenize(line, ",")
        #             if (id := int(tokens[2])) not in mdict:
        #                 mdict[id] = {}
        #             if (property := tokens[1]) not in ("UVID", "UMID"):
        #                 mdict[id][property] = float(tokens[3])

        # Convert to Material instances:
        # for id, m in mdict.items():
        #     if "EY" in m:
        #         mdict[id] = Material(
        #             E1=m["EX"],
        #             E2=m["EY"],
        #             E3=m["EZ"],
        #             nu12=m["PRXY"],
        #             nu23=m["PRYZ"],
        #             nu13=m["PRXZ"],
        #             G23=m["GYZ"],
        #             G13=m["GXZ"],
        #             G12=m["GXY"],
        #             rho=m["DENS"],
        #         )
        #     else:
        #         mdict[id] = Material.isotropic(
        #             E=m["EX"],
        #             nu=m["NUXY"],
        #             rho=m["DENS"],
        #         )

        connectivity: list[NDArray] = []
        element_types: list[ElementType] = []
        for element_type, element in zip(self.mapdl.mesh.etype, self.mapdl.mesh.elem):
            match element_type:
                case 185:
                    connectivity.append(element[10:] - 1)
                    element_types.append(ElementType.HEX8)
                case 186:
                    connectivity.append(element[10:] - 1)
                    element_types.append(ElementType.HEX20)
                case 187:
                    connectivity.append(element[10:] - 1)
                    element_types.append(ElementType.TET10)
                case 285:
                    connectivity.append(element[10:] - 1)
                    element_types.append(ElementType.TET4)
                case _:
                    pass

        if any(type != element_types[0] for type in element_types):
            raise ValueError("Meshes with multiple element types are not supported yet.")

        return Mesh(
            nodes=nodes,
            element_type=element_types[0],
            element_connectivity=numpy.array(connectivity, dtype=numpy.int32),
        )

    def get_analysis(self) -> Analysis:
        start = timer()

        mesh = self.get_mesh()

        dummy_material = TransverselyIsotropicMaterial(
            E1=209000,
            E2=9450,
            nu12=0.27,
            G23=3900,
            G12=5500,
            rho=1.54e-9,
        )

        # TODO: Parse DBCs directly from ds.dat.
        dlist: str = self.mapdl.dlist()
        lines: list[str] = dlist.splitlines()
        dbc: list[BC] = []
        for line in lines:
            tokens = line.split()
            node = int(tokens[0]) - 1
            displacement = float(tokens[2])
            match tokens[1]:
                case "UX":
                    direction = Axis.X
                case "UY":
                    direction = Axis.Y
                case "UZ":
                    direction = Axis.Z
                case _:
                    raise ValueError(f"Unknown direction in DLIST: {tokens[1]}")
            dbc.append(
                BC(
                    node=node,
                    direction=direction,
                    value=displacement,
                )
            )

        # TODO: Parse NBCs directly from ds.dat.
        dummy_nbc = []

        logger.info(f"Analysis parsed in {round(timer() - start, 3)} seconds.")

        return Analysis(
            mesh=mesh,
            material=dummy_material,
            dbc=dbc,
            nbc=dummy_nbc,
        )
